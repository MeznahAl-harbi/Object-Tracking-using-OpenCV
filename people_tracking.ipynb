{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a57cd4b",
   "metadata": {},
   "source": [
    "# ðŸ‘ï¸ Object Tracking with OpenCV + MobileNetSSD \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06da26",
   "metadata": {},
   "source": [
    "ðŸ“¦ Install OpenCV library\n",
    "\n",
    "> ðŸ’¡ Note: Run `pip install opencv-python` in the terminal, not in a code cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58045f92",
   "metadata": {},
   "source": [
    " ðŸ” Model Used:\n",
    "MobileNet-SSD (Caffe model)  \n",
    "Source: https://github.com/chuanqi305/MobileNet-SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424600f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62ebca25",
   "metadata": {},
   "source": [
    "Person Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3891cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# === Load the MobileNet SSD model for person detection ===\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    r\"C:\\Users\\iphon\\Desktop\\Training projects\\object-tracking-opencv\\deploy.prototxt.txt\",\n",
    "    r\"C:\\Users\\iphon\\Desktop\\Training projects\\object-tracking-opencv\\mobilenet_iter_73000.caffemodel\"\n",
    ")\n",
    "\n",
    "# === Load the video file or camera ===\n",
    "# cap = cv2.VideoCapture(0) # Uncomment for webcam\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\iphon\\Desktop\\Training projects\\object-tracking-opencv\\video.MP4\")\n",
    "\n",
    "# === Check if video opened successfully ===\n",
    "if not cap.isOpened():\n",
    "    print(\"âŒ Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# === Get video properties for saving ===\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# === Create VideoWriter object to save output video ===\n",
    "out = cv2.VideoWriter(\n",
    "    'output.avi',\n",
    "    cv2.VideoWriter_fourcc(*'XVID'),\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "# === Create a CSRT tracker ===\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "init_tracker = False\n",
    "\n",
    "# === Start reading video frames ===\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if not init_tracker:\n",
    "        # === Perform object detection on the first frame ===\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        # === Loop through all detections ===\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "            # === Check if the detected object is a person and confidence > 0.5 ===\n",
    "            if confidence > 0.5 and class_id == 15:\n",
    "                box = detections[0, 0, i, 3:7] * \\\n",
    "                      [frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]]\n",
    "                (x, y, x1, y1) = box.astype(\"int\")\n",
    "                bbox = (x, y, x1 - x, y1 - y)\n",
    "\n",
    "                # === Initialize the tracker with the bounding box ===\n",
    "                tracker.init(frame, bbox)\n",
    "                init_tracker = True\n",
    "                break\n",
    "    else:\n",
    "        # === Update tracker on new frame ===\n",
    "        success, bbox = tracker.update(frame)\n",
    "        if success:\n",
    "            (x, y, w, h) = [int(i) for i in bbox]\n",
    "            \n",
    "            # === Draw the bounding box and label ===\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Person\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # === Save the frame to output video ===\n",
    "    out.write(frame)\n",
    "\n",
    "    # === Display the frame ===\n",
    "    cv2.imshow(\"People Tracking\", frame)\n",
    "\n",
    "    # === Exit when ESC key is pressed ===\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# === Release resources ===\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd99cc5",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Final Notes\n",
    "\n",
    "- Press `ESC` to stop the tracking.\n",
    "- You can switch between webcam or video file by commenting/uncommenting the related line.\n",
    "- Tested on Python 3.10 + OpenCV 4.x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
